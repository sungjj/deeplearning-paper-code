{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upEJK8UUDnyn"
   },
   "source": [
    "> ### EEE4423: Deep Learning Lab\n",
    "\n",
    "# LAB \\#12: Sequence to Sequence Network with Attention Module\n",
    "## Machine Translation with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAv1aaG8Dnys"
   },
   "source": [
    "<h4><div style=\"text-align: right\"> Due date: May 27, 2022. </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file @ LearnUs by 9 AM in the form of [ID_Name_Lab12.ipynb]. </div></h4>\n",
    "\n",
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span> \n",
    "- Each team must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SULIl9bRDnys"
   },
   "source": [
    "<h2><span style=\"color:blue\">[2019142079] [성재진]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2JP0LD9nDnys",
    "outputId": "0c1a8aae-4843-435b-dbaa-9624d918ff03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2023-05-25 03:18:36.429045\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBvC_gonDnyu"
   },
   "source": [
    "In this project we will be teaching a neural network to translate from\n",
    "French to English.\n",
    "*************************************************************\n",
    "::\n",
    "\n",
    "    [(>): input, (=): target, (<): output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "...\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nLSIcUoZDnyu"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v0s8XW7Dnyv"
   },
   "source": [
    "### 1. Prepare data\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs. Download the data from <https://download.pytorch.org/tutorial/data.zip>. The file is a tab separated list of translation pairs:\n",
    "\n",
    "\n",
    "    I am cold.    J'ai froid.\n",
    "    \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1K3W2RxeTKih5IiT5PcIyWNZSwMqtYSGZ\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xn2soUCGDnyv",
    "outputId": "a76ed812-6017-4ceb-a52c-2fd70a6b1377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counted words: fra = 4345 eng = 2803\n",
      "['tu es trop tendue .', 'you re too tense .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 10\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \")\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./dataset-dllab/lab12/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\", input_lang.name, '=', input_lang.n_words, output_lang.name, '=', output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A8yVC59WDnyw"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4qXkB3DDnyw"
   },
   "source": [
    "### 2. Build the Seq2Seq model [5 points]\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1kKXrIIxi0t-Nm5HfzOukqjzEp7yEXEpV\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "[sequence to sequence network](https://arxiv.org/abs/1409.3215) is a model in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a single vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDTwMr5TDnyy"
   },
   "source": [
    "#### Encoder\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.  \n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1PyKBEVl5jwQfB0I0P2kG8nTGQVZQdZEM\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "#### GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1467jVFRYbw1DYvVKeSyzGWLRmtlqpy8z\"  onerror=\"this.style.display='none'\" style=\"width: 700px;\"/><br><br>\n",
    "The GRU operates using a reset gate (r) and an update gate (z). The candidate state is created by using the previous hidden state and the current input. It is the reset gate that determines how the previous hidden state affects the candidate state. The newly created candidate state and the previous hidden state create a new hidden state, in which the update gate plays a role in balancing the two.\n",
    "\n",
    "#### LSTM vs GRU\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1lzGTsIYvPWKNF-XaTevMaaZvjfgp9G35\"  onerror=\"this.style.display='none'\" style=\"width: 600px;\"/><br><br>\n",
    "\n",
    "| <center>LSTM</center> | <center>GRU</center>  |\n",
    "|:--------|--------|\n",
    "| LSTM has 3 gates (forget, input, output) | GRU has 2 gates (reset, update) |\n",
    "| There is an internal memory (cell state) | There is no cell state and only hidden state exists |\n",
    "| When making output, another non-linearity is applied | There is no additional non-linearity when making output  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PpL3bajyDnyy"
   },
   "outputs": [],
   "source": [
    "# 2 points\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        # gru\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        #주어진 공식을 만들기 위해 matrix를 linear로 정의해준다.\n",
    "        self.U_z = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_z = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.U_r = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_r = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.U_h = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_h = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.tanh=nn.Tanh()\n",
    "        #############\n",
    "\n",
    "    def forward(self, input, hn):\n",
    "        #############\n",
    "        #input을 embedding하고 GRU의 gate를 위에 주어진 공식대로 적어준다.\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        z_t=self.sigmoid(self.U_z(embedded)+self.W_z(hn))\n",
    "        r_t=self.sigmoid(self.U_r(embedded)+self.W_r(hn))\n",
    "        h_tilde_t=self.tanh(self.U_h(embedded)+self.W_h(hn*r_t))\n",
    "        hn=(1-z_t)*h_tilde_t+z_t*hn\n",
    "        output=hn\n",
    "        #############\n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        h0 = torch.zeros(1,1, self.hidden_dim).cuda()#hidden state initializ\n",
    "        #############\n",
    "        return h0\n",
    "    \n",
    "hidden_dim = 256\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGjPPHD7Dnyy"
   },
   "source": [
    "#### Decoder\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1Rm_LlpEolCvPuzPWEFOZ-zdTfsgMbtu-\"  onerror=\"this.style.display='none'\" /><br><br>\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder, that single vector carries the burden of encoding the entire sentence. Attention allows the decoder network to \"focus\" on a specific part of\n",
    "the encoder's outputs for every step and thus help the decoder choose the right output words. \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=18hsS8PAA7I3QaN9oOebfnMGAMhR-6EID\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1F1Y92uLvGaI6s-ygyNKNox4ZGiZmTZ3g\"  onerror=\"this.style.display='none'\" style=\"width: 170px;\"/><br><br>\n",
    "\n",
    "The attention weights are calculated using an another feed-forward layer which inputs the decoder's input and hidden state. And the calculated attention weight is multiplied to the corresponding hidden state of the encoder, respectively. Note that to actually create and train this layer we have to choose a maximum sentence length. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1JEE23gtJf4XciJUXLt2R9lZtpRn8mYCN\"  onerror=\"this.style.display='none'\" /><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NfWr22rFDnyz"
   },
   "outputs": [],
   "source": [
    "# 3 points\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_dim, self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        # attention\n",
    "        # Note that the column of the attention weights is MAX_LENGTH\n",
    "        # Note that concatenation is used when \"attn\" and \"attn_combine\" are created\n",
    "        #############\n",
    "        #위의 그림처럼 attn과 attn_combine을 만들어준다.\n",
    "        self.attn = nn.Linear(self.hidden_dim * 2, MAX_LENGTH)#prev_hidden과 embedded가 concatenate\n",
    "        self.attn_combine = nn.Linear(self.hidden_dim * 2, self.hidden_dim)#attn_applied와 embedded가 concatenate\n",
    "        #############\n",
    "        \n",
    "        # gru\n",
    "        # The size of input is (batch_size, seq_dim, hidden_dim)\n",
    "        #############\n",
    "        #encoder와 같다.\n",
    "        self.U_z = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_z = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.U_r = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_r = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.U_h = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.W_h = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.tanh=nn.Tanh()\n",
    "        #############\n",
    "        \n",
    "        self.out = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, input, hn, encoder_outputs):\n",
    "        input= self.embedding(input).view(1, 1, -1)#input_embedding\n",
    "        input = self.dropout(input)#impu_dropout\n",
    "        \n",
    "        # attention\n",
    "        # All specifications of the operations are described in the above figure (e.g. use ReLU)\n",
    "        # bmm is a operation which performs a batch matrix-matrix product\n",
    "        #############\n",
    "        #주어진 그래프대로 수행한다.\n",
    "        attn=self.attn(torch.cat((input, hn), 2))\n",
    "        attn_weights = F.softmax(attn, dim=2)\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_outputs.unsqueeze(0))\n",
    "        attn_combine = torch.cat((input, attn_applied), 2)\n",
    "        attn_combine = self.attn_combine(attn_combine)\n",
    "        attn_combine = F.relu(attn_combine)\n",
    "        #############\n",
    "        \n",
    "        # gru\n",
    "        #############\n",
    "        #encoder와 같다.\n",
    "        z_t=self.sigmoid(self.U_z(attn_combine)+self.W_z(hn))\n",
    "        r_t=self.sigmoid(self.U_r(attn_combine)+self.W_r(hn))\n",
    "        h_tilde_t=self.tanh(self.U_h(attn_combine)+self.W_h(hn*r_t))\n",
    "        hn=(1-z_t)*h_tilde_t+z_t*hn\n",
    "        output=hn\n",
    "        #############\n",
    "        \n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hn\n",
    "\n",
    "    def initHidden(self):\n",
    "        # The size of h0 should be (layer_dim, batch_size, hidden_dim)\n",
    "        #############\n",
    "        h0 = torch.zeros(1, 1, hidden_dim, device=device) #hidden state initialize\n",
    "        #############\n",
    "        return h0\n",
    "    \n",
    "decoder = AttnDecoderRNN(hidden_dim, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg2utJ-1Dnyz"
   },
   "source": [
    "### 3. Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KE-npWCODnyz"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "learning_rate=0.01\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMr9RcDBDnyz"
   },
   "source": [
    "### 4. Write the evaluation code [2 points]\n",
    "\n",
    "- Using the trained model, display the translated output given input sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UO3UzfFCDnyz"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        #############\n",
    "        encoder_hidden = encoder.initHidden() #encoder hidden state initialize\n",
    "        #############\n",
    "        \n",
    "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoded_words = []\n",
    "        #############\n",
    "        for i in range(input_length):#input_length만큼 반복\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)#encoder로 부터 나온 output과 hidden\n",
    "            encoder_outputs[i] += encoder_output.reshape(-1)#배열에 넣어준다\n",
    "        decoder_hidden = encoder_hidden\n",
    "        for i in range(MAX_LENGTH):#MAX_LENGTH만큼 반복\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)#decoder로 부터 나온 output과 hidden\n",
    "            topv, topi = decoder_output.data.topk(1)#가장 확률이 높은 단어\n",
    "            if topi.item() == EOS_token:#문장이 끝난거면 break\n",
    "                break  \n",
    "            decoded_words.append(output_lang.index2word[topi.item()])#가장 확률이 높은 단어를 출력한다.\n",
    "            decoder_input = topi.squeeze().detach()#디코더의 다음 input은 output에서 가장 확률 높은 단어의 index\n",
    "        #############\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "def evaluateRandomly():\n",
    "    pair = random.choice(pairs)\n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7wNENhXDnyz"
   },
   "source": [
    "### 5 . Write the code to train the model [3 points]\n",
    "\n",
    "- During training, use the `Teacher forcing` concept in addition to a naive approach.\n",
    "    - In other words, instead of using the decoder's guess as the next input, the real target outputs are also used sometimes. This shows faster convergence.\n",
    "- Plot the training loss curve.\n",
    "- Show the result using $evaluateRandomly()$ function. Below is an example.\n",
    "*************************************************************\n",
    "    > il est en train de peindre un tableau . (input)\n",
    "    = he is painting a picture . (target)\n",
    "    < he is painting a picture . (output)\n",
    "*************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio=0.5 #reference [1] 에 나와있는대로 teacher_forcing_ratio를 0.5로 정했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9x83bK3GDnyz",
    "outputId": "34533830-f22b-4080-bc51-582d4993b8e2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* iter1000 *************************\n",
      "loss 10.4009\n",
      "> elle a l air de venir .\n",
      "= she is likely to come .\n",
      "< i m not .\n",
      "\n",
      "************************* iter2000 *************************\n",
      "loss 10.1759\n",
      "> ils sont speciaux .\n",
      "= they re special .\n",
      "< they re very .\n",
      "\n",
      "************************* iter3000 *************************\n",
      "loss 19.8161\n",
      "> je suis juste un peu pris de vertiges .\n",
      "= i m just a little dizzy .\n",
      "< i m a a to . . . . .\n",
      "\n",
      "************************* iter4000 *************************\n",
      "loss 22.2906\n",
      "> nous sommes tellement contentes de vous avoir ici !\n",
      "= we re so glad to have you here .\n",
      "< we re going to you .\n",
      "\n",
      "************************* iter5000 *************************\n",
      "loss 12.9816\n",
      "> vous n etes pas un saint .\n",
      "= you re no saint .\n",
      "< you re not a . .\n",
      "\n",
      "************************* iter6000 *************************\n",
      "loss 41.4113\n",
      "> en un sens tu as raison .\n",
      "= you are right in a way .\n",
      "< he is a good to . . .\n",
      "\n",
      "************************* iter7000 *************************\n",
      "loss 12.2982\n",
      "> c est un mannequin d elite .\n",
      "= she s a supermodel .\n",
      "< he s a bit .\n",
      "\n",
      "************************* iter8000 *************************\n",
      "loss 8.7018\n",
      "> tu es l elue .\n",
      "= you are the one .\n",
      "< you re the one .\n",
      "\n",
      "************************* iter9000 *************************\n",
      "loss 12.5511\n",
      "> c est vous le doyen .\n",
      "= you re the oldest .\n",
      "< you re the the .\n",
      "\n",
      "************************* iter10000 *************************\n",
      "loss 10.9378\n",
      "> ma journee est tres dure aujourd hui .\n",
      "= i m having a very difficult time today .\n",
      "< she is very very nice .\n",
      "\n",
      "************************* iter11000 *************************\n",
      "loss 33.2825\n",
      "> je suis totalement d accord .\n",
      "= i m in absolutely total agreement .\n",
      "< i m tired of . .\n",
      "\n",
      "************************* iter12000 *************************\n",
      "loss 16.7361\n",
      "> il n est pas un saint .\n",
      "= he s no saint .\n",
      "< he is no a doctor .\n",
      "\n",
      "************************* iter13000 *************************\n",
      "loss 13.3742\n",
      "> elle chante les derniers tubes .\n",
      "= she is singing the latest popular songs .\n",
      "< she is wearing on his . .\n",
      "\n",
      "************************* iter14000 *************************\n",
      "loss 8.9186\n",
      "> nous n en avons pas encore termine .\n",
      "= we re not done yet .\n",
      "< we re not yet yet .\n",
      "\n",
      "************************* iter15000 *************************\n",
      "loss 13.0901\n",
      "> nous sommes jumelles .\n",
      "= we re twins .\n",
      "< we re ready .\n",
      "\n",
      "************************* iter16000 *************************\n",
      "loss 4.1065\n",
      "> nous ne sommes pas responsables .\n",
      "= we re not responsible .\n",
      "< we re not good .\n",
      "\n",
      "************************* iter17000 *************************\n",
      "loss 8.3775\n",
      "> elles sont bonnes toutes les deux .\n",
      "= they are both good .\n",
      "< they re all good .\n",
      "\n",
      "************************* iter18000 *************************\n",
      "loss 4.0957\n",
      "> il est probable qu il remporte le jeu .\n",
      "= he is likely to win the game .\n",
      "< he is likely to the the the .\n",
      "\n",
      "************************* iter19000 *************************\n",
      "loss 21.4411\n",
      "> elle a divorce .\n",
      "= she s divorced .\n",
      "< she s getting .\n",
      "\n",
      "************************* iter20000 *************************\n",
      "loss 11.9969\n",
      "> j ai encore soif .\n",
      "= i m still thirsty .\n",
      "< i m still hungry .\n",
      "\n",
      "************************* iter21000 *************************\n",
      "loss 32.0071\n",
      "> tu n es pas une sainte .\n",
      "= you re no saint .\n",
      "< you re not a . .\n",
      "\n",
      "************************* iter22000 *************************\n",
      "loss 6.3706\n",
      "> tu es plus grande qu elle .\n",
      "= you are taller than she is .\n",
      "< you are taller than she is .\n",
      "\n",
      "************************* iter23000 *************************\n",
      "loss 10.1019\n",
      "> vous n etes pas encore morte .\n",
      "= you re not dead yet .\n",
      "< you re not dead yet .\n",
      "\n",
      "************************* iter24000 *************************\n",
      "loss 14.3495\n",
      "> nous sommes maintenant prets .\n",
      "= we re ready now .\n",
      "< we re all good now .\n",
      "\n",
      "************************* iter25000 *************************\n",
      "loss 0.4940\n",
      "> c est un etudiant de premier cycle .\n",
      "= he s an undergrad .\n",
      "< he is a a . . .\n",
      "\n",
      "************************* iter26000 *************************\n",
      "loss 1.0903\n",
      "> elle apprend a jouer du piano .\n",
      "= she is learning the piano .\n",
      "< she is going to the the . .\n",
      "\n",
      "************************* iter27000 *************************\n",
      "loss 26.1887\n",
      "> je suis aime de ma mere .\n",
      "= i am loved by my mother .\n",
      "< i m very my my friends .\n",
      "\n",
      "************************* iter28000 *************************\n",
      "loss 0.9225\n",
      "> j en ai marre d ecouter ses plaintes .\n",
      "= i m sick of listening to her complaints .\n",
      "< i m tired of listening to her her .\n",
      "\n",
      "************************* iter29000 *************************\n",
      "loss 13.2932\n",
      "> je suis etudiant .\n",
      "= i am a university student .\n",
      "< i am a student .\n",
      "\n",
      "************************* iter30000 *************************\n",
      "loss 3.2120\n",
      "> je suis desole .\n",
      "= i am sorry .\n",
      "< i m sorry .\n",
      "\n",
      "************************* iter31000 *************************\n",
      "loss 10.2850\n",
      "> elle a une forte volonte .\n",
      "= she s strong willed .\n",
      "< she s getting a a . .\n",
      "\n",
      "************************* iter32000 *************************\n",
      "loss 4.4572\n",
      "> tu es la personne la plus grande ici .\n",
      "= you re the tallest person here .\n",
      "< you re the master here .\n",
      "\n",
      "************************* iter33000 *************************\n",
      "loss 3.1503\n",
      "> le bleu vous va tres bien .\n",
      "= you are very attractive in blue .\n",
      "< you re not very good this .\n",
      "\n",
      "************************* iter34000 *************************\n",
      "loss 11.2433\n",
      "> vous etes dans la merde .\n",
      "= you re in big trouble .\n",
      "< you are in in . .\n",
      "\n",
      "************************* iter35000 *************************\n",
      "loss 2.1820\n",
      "> il est mauvais conducteur .\n",
      "= he is a bad driver .\n",
      "< he s a good writer .\n",
      "\n",
      "************************* iter36000 *************************\n",
      "loss 22.7223\n",
      "> je suis touchee .\n",
      "= i m touched .\n",
      "< i m fat .\n",
      "\n",
      "************************* iter37000 *************************\n",
      "loss 1.9739\n",
      "> ils sont faibles .\n",
      "= they re weak .\n",
      "< they re similar .\n",
      "\n",
      "************************* iter38000 *************************\n",
      "loss 2.4880\n",
      "> je suis desolee je ne te remets pas .\n",
      "= i m sorry i don t recognize you .\n",
      "< i m sorry i don t recognize you .\n",
      "\n",
      "************************* iter39000 *************************\n",
      "loss 0.6408\n",
      "> vous etes fascinant .\n",
      "= you re fascinating .\n",
      "< you re a .\n",
      "\n",
      "************************* iter40000 *************************\n",
      "loss 13.6614\n",
      "> il est tres mechant avec moi .\n",
      "= he is very mean to me .\n",
      "< he is very nice to me .\n",
      "\n",
      "************************* iter41000 *************************\n",
      "loss 3.3218\n",
      "> nous n allons pas le jeter .\n",
      "= we re not throwing it away .\n",
      "< we re not going to it .\n",
      "\n",
      "************************* iter42000 *************************\n",
      "loss 1.1285\n",
      "> il ramasse l argent a la pelle .\n",
      "= he s raking it in .\n",
      "< he s raking it in the game .\n",
      "\n",
      "************************* iter43000 *************************\n",
      "loss 5.4694\n",
      "> vous etes courtois .\n",
      "= you re courteous .\n",
      "< you re courteous .\n",
      "\n",
      "************************* iter44000 *************************\n",
      "loss 0.8003\n",
      "> c est vous l instituteur .\n",
      "= you re the teacher .\n",
      "< you re the teacher .\n",
      "\n",
      "************************* iter45000 *************************\n",
      "loss 16.6066\n",
      "> on s amuse avec elle .\n",
      "= she is amusing to be with .\n",
      "< she is with to be her .\n",
      "\n",
      "************************* iter46000 *************************\n",
      "loss 3.1794\n",
      "> je suis curieux .\n",
      "= i m curious .\n",
      "< i m curious .\n",
      "\n",
      "************************* iter47000 *************************\n",
      "loss 1.4627\n",
      "> je suis tres fier de ma fille .\n",
      "= i m very proud of my daughter .\n",
      "< i m very kind of my girl .\n",
      "\n",
      "************************* iter48000 *************************\n",
      "loss 19.6297\n",
      "> vous etes riches n est ce pas ?\n",
      "= you re wealthy aren t you ?\n",
      "< you re worried aren t you ?\n",
      "\n",
      "************************* iter49000 *************************\n",
      "loss 2.0616\n",
      "> je suis un inconditionnel de l opera allemand .\n",
      "= i m a fan of german opera .\n",
      "< i m a man of this .\n",
      "\n",
      "************************* iter50000 *************************\n",
      "loss 1.4801\n",
      "> c est toi la professeur .\n",
      "= you re the teacher .\n",
      "< you re the teacher .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fac13697e10>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iters = 50000\n",
    "print_every = 1000\n",
    "plot_every =100\n",
    "\n",
    "plot_losses = []\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "for iter in range(1, n_iters+1):\n",
    "    # Load data\n",
    "    training_pair = training_pairs[iter-1]\n",
    "    input_tensor = training_pair[0]\n",
    "    target_tensor = training_pair[1]\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    #############\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #############\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #############\n",
    "    #hidden state initialization\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    decoder_hidden = decoder.initHidden()\n",
    "    #############\n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "    #############\n",
    "    #encoder로 부터 output과 hidden을 추출하여 output을 배열에 넣어준다.\n",
    "    for i in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_output.reshape(-1)\n",
    "    #############\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    #############\n",
    "    decoder_hidden = encoder_hidden\n",
    "    #0.5의 확률로 랜덤하게 teacher_forcing이 되도록 했다.\n",
    "    use_teacher_forcing=random.random()>teacher_forcing_ratio\n",
    "    if use_teacher_forcing:#teacher forcing이 될 때    \n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[i])\n",
    "            decoder_input = target_tensor[i] #real target output이 다음 input이 되도록\n",
    "    else:#teacher forcing이 되지 않을 때\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[i])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            #decoder가 추측한 단어가 다음 input이 되도록\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "    #############\n",
    "\n",
    "    # Backward pass\n",
    "    #############\n",
    "    loss.backward()\n",
    "    #############\n",
    "\n",
    "    # Updating parameters\n",
    "    #############\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #############\n",
    "    \n",
    "    print_loss_total += loss.item() / target_length\n",
    "    plot_loss_total += loss.item() / target_length\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('*'*25, 'iter%d'%iter, '*'*25)\n",
    "        print('loss %.4f'%loss)\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        evaluateRandomly()\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "#################################################\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrccVZ1gDny0"
   },
   "source": [
    "### *References*\n",
    "[1] [practical pytorch](https://github.com/spro/practical-pytorch)(https://github.com/spro/practical-pytorch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Discussion*\n",
    "이번에는 GRU를 구현하였다. GRU는 LSTM과 성능은 비슷하지만 LSTM의 복잡한 구조를 간단하게 만들었다. gate가 2개이고 cell state가 없으며 output을 출력할 때 추가적인 non-linearity가 필요없다. decoder에서는 Attention을 사용하였다. Attention을 사용하지 않으면 단일 벡터가 문장 전체를 encoding해야 하는데 Attention을 사용하면 decoder가 모든 step에 대한 encoder output의 특정 부분에 집중할 수 있어 더 좋은 성능이 나온다. train을 할때는 teacher forcing 기법을 사용했는데 항상 decoder가 예측한 다음 단어를 다음 input으로 사용하는 것이 아니라 특정확률로 real target output을 다음 input으로 사용하는 것이다.\n",
    "\n",
    "experiment는 프랑스어를 영어로 번역하는 것이다. 결과를 살펴보면 \"you re the teacher .\"같은 간단한 문장은 잘 해석하지만 \"i m a fan of german opera .\"같은 문장은 잘 해석하지 못한다. 또한 문장의 형식은 유사하게 갖추나 명사같이 일부분만 틀리는 경우도 있다. 저번과 마찬가지로 그래프에서의 loss와 print된 loss의 scale이 다른 것을 볼 수 있는데 print로 출력할 때 그냥 loss를 출력하기 때문이다. print_loss_avg를 출력하는 것이 합리적이라고 생각한다. teacher forcing 기법을 사용하지 않았을 때의 결과를 살펴보기 위해 추가적인 실험을 진행하였고 결과는 아래에 첨부하였다. teacher forcing 기법을 사용할때보다 loss가 줄어드는 속도가 느리다.\n",
    "\n",
    "데이터가 저번과 같은 sequence이고, 모델 구조가 LSTM보다 단순하다 보니 저번 주의 실험보다는 구현하는 것이 쉬웠다. 번역은 정확도가 중요한데 결과물을 보니 의미가 완전 다른 문장들이 많이 보였다. 추후에 gpt나 transformer같은 최신 모델로 실험해보고 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio=1 #teacher forcing 기법을 사용하지 않기 위해 teacher_forcing_ratio를 1로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* iter1000 *************************\n",
      "loss 21.1812\n",
      "> je ne suis pas bon dans la simulation .\n",
      "= i m not good at pretending .\n",
      "< i m not the . .\n",
      "\n",
      "************************* iter2000 *************************\n",
      "loss 11.7281\n",
      "> elles sont toutes mortes .\n",
      "= they re all dead .\n",
      "< they re very . .\n",
      "\n",
      "************************* iter3000 *************************\n",
      "loss 12.1315\n",
      "> tu caches quelque chose .\n",
      "= you re hiding something .\n",
      "< you re very good .\n",
      "\n",
      "************************* iter4000 *************************\n",
      "loss 14.5318\n",
      "> tu es cerne .\n",
      "= you re surrounded .\n",
      "< you re the .\n",
      "\n",
      "************************* iter5000 *************************\n",
      "loss 18.5824\n",
      "> je fais encore mon marche .\n",
      "= i m still shopping around .\n",
      "< i m looking to my . .\n",
      "\n",
      "************************* iter6000 *************************\n",
      "loss 10.2300\n",
      "> elle est plus une relation qu une amie .\n",
      "= she is more an acquaintance than a friend .\n",
      "< she s a a a . .\n",
      "\n",
      "************************* iter7000 *************************\n",
      "loss 19.0934\n",
      "> ils sont tres bienveillants .\n",
      "= they are very kind .\n",
      "< they re very curious .\n",
      "\n",
      "************************* iter8000 *************************\n",
      "loss 11.7340\n",
      "> tu es trop jeune pour voyager seule .\n",
      "= you are too young to travel alone .\n",
      "< you re too to to . . .\n",
      "\n",
      "************************* iter9000 *************************\n",
      "loss 18.5370\n",
      "> elle est pauvre mais elle est heureuse .\n",
      "= she is poor but she is happy .\n",
      "< she is a a a . . .\n",
      "\n",
      "************************* iter10000 *************************\n",
      "loss 23.5572\n",
      "> je ne suis pas encore marie .\n",
      "= i m not married yet .\n",
      "< i m not not .\n",
      "\n",
      "************************* iter11000 *************************\n",
      "loss 21.3631\n",
      "> il ne s y rend pas .\n",
      "= he s not going .\n",
      "< he s not not to . .\n",
      "\n",
      "************************* iter12000 *************************\n",
      "loss 8.6010\n",
      "> je ne suis pas folle .\n",
      "= i m not crazy .\n",
      "< i m not sure .\n",
      "\n",
      "************************* iter13000 *************************\n",
      "loss 33.3640\n",
      "> je me rejouis que tu sois ici .\n",
      "= i m glad that you re here .\n",
      "< i m glad you re here here .\n",
      "\n",
      "************************* iter14000 *************************\n",
      "loss 23.1943\n",
      "> elle est en train de l embrasser .\n",
      "= she is kissing him .\n",
      "< she is the .\n",
      "\n",
      "************************* iter15000 *************************\n",
      "loss 21.9622\n",
      "> tu es tellement difficile !\n",
      "= you re so picky .\n",
      "< you re so sorry !\n",
      "\n",
      "************************* iter16000 *************************\n",
      "loss 27.2778\n",
      "> je suis trop vieille pour ca .\n",
      "= i m too old for this .\n",
      "< i m too old for . .\n",
      "\n",
      "************************* iter17000 *************************\n",
      "loss 9.6305\n",
      "> elle est toujours soigneusement habillee .\n",
      "= she is always neatly dressed .\n",
      "< she is always always his . .\n",
      "\n",
      "************************* iter18000 *************************\n",
      "loss 12.4568\n",
      "> nous allons encore etre en retard .\n",
      "= we re going to be late again .\n",
      "< we re going going to .\n",
      "\n",
      "************************* iter19000 *************************\n",
      "loss 8.5778\n",
      "> il ne cesse de me surprendre .\n",
      "= i m always surprised by him .\n",
      "< he s afraid to go . .\n",
      "\n",
      "************************* iter20000 *************************\n",
      "loss 22.8864\n",
      "> elle demande l impossible .\n",
      "= she s asking for the impossible .\n",
      "< she s waiting for the .\n",
      "\n",
      "************************* iter21000 *************************\n",
      "loss 7.3928\n",
      "> je manque d espace dans mon placard .\n",
      "= i m running out of closet space .\n",
      "< i m going of my my my my\n",
      "\n",
      "************************* iter22000 *************************\n",
      "loss 16.3599\n",
      "> tu es la meilleure .\n",
      "= you re the greatest .\n",
      "< you re the leader .\n",
      "\n",
      "************************* iter23000 *************************\n",
      "loss 13.3978\n",
      "> tu es riche n est ce pas ?\n",
      "= you re wealthy aren t you ?\n",
      "< you re a aren aren t ? ?\n",
      "\n",
      "************************* iter24000 *************************\n",
      "loss 10.3081\n",
      "> il l a fait auparavant .\n",
      "= he s done it before .\n",
      "< he s done the right .\n",
      "\n",
      "************************* iter25000 *************************\n",
      "loss 6.3717\n",
      "> elle est hors sujet .\n",
      "= she is missing the point .\n",
      "< she s about the .\n",
      "\n",
      "************************* iter26000 *************************\n",
      "loss 19.8281\n",
      "> nous allons au devant d un desastre .\n",
      "= we re heading for disaster .\n",
      "< we re going to have a a . .\n",
      "\n",
      "************************* iter27000 *************************\n",
      "loss 4.9996\n",
      "> je suis tres flatte d entendre cela .\n",
      "= i m really flattered to hear that .\n",
      "< i m very sure to hear that .\n",
      "\n",
      "************************* iter28000 *************************\n",
      "loss 4.3779\n",
      "> ils sont sympa .\n",
      "= they re cool .\n",
      "< they re students .\n",
      "\n",
      "************************* iter29000 *************************\n",
      "loss 10.7984\n",
      "> vous etes inquiete n est ce pas ?\n",
      "= you re worried aren t you ?\n",
      "< you re depressed aren t you ?\n",
      "\n",
      "************************* iter30000 *************************\n",
      "loss 24.9257\n",
      "> elles s ennuient .\n",
      "= they are bored .\n",
      "< they are gone .\n",
      "\n",
      "************************* iter31000 *************************\n",
      "loss 19.1749\n",
      "> tu n es pas censee fumer ici .\n",
      "= you are not supposed to smoke here .\n",
      "< you re no supposed to swim here .\n",
      "\n",
      "************************* iter32000 *************************\n",
      "loss 25.1613\n",
      "> nous n allons nulle part .\n",
      "= we re not going anywhere .\n",
      "< we re not going anywhere .\n",
      "\n",
      "************************* iter33000 *************************\n",
      "loss 0.5263\n",
      "> nous demissionnons .\n",
      "= we re resigning .\n",
      "< we re resigning .\n",
      "\n",
      "************************* iter34000 *************************\n",
      "loss 4.9738\n",
      "> nous sommes impitoyables .\n",
      "= we re ruthless .\n",
      "< we re powerful .\n",
      "\n",
      "************************* iter35000 *************************\n",
      "loss 5.0595\n",
      "> je ne suis pas facilement offensee .\n",
      "= i m not easily offended .\n",
      "< i m not a . .\n",
      "\n",
      "************************* iter36000 *************************\n",
      "loss 6.5950\n",
      "> tu es tres chouette .\n",
      "= you re very nice .\n",
      "< you re very nice .\n",
      "\n",
      "************************* iter37000 *************************\n",
      "loss 8.8827\n",
      "> elle est l editeur en chef .\n",
      "= she is the editor in chief .\n",
      "< she is the . .\n",
      "\n",
      "************************* iter38000 *************************\n",
      "loss 9.2172\n",
      "> c est une femme determinee .\n",
      "= she s a determined woman .\n",
      "< she is a woman woman .\n",
      "\n",
      "************************* iter39000 *************************\n",
      "loss 9.2249\n",
      "> il est sur le chemin de son domicile .\n",
      "= he s on his way home .\n",
      "< he is on the . . .\n",
      "\n",
      "************************* iter40000 *************************\n",
      "loss 8.3814\n",
      "> je suis agriculteur .\n",
      "= i m a farmer .\n",
      "< i m a .\n",
      "\n",
      "************************* iter41000 *************************\n",
      "loss 1.8217\n",
      "> vous etes talentueuses .\n",
      "= you re talented .\n",
      "< you re crafty .\n",
      "\n",
      "************************* iter42000 *************************\n",
      "loss 5.5181\n",
      "> ils sont sur le point de partir .\n",
      "= they re about to leave .\n",
      "< they re about to go .\n",
      "\n",
      "************************* iter43000 *************************\n",
      "loss 0.7616\n",
      "> ils partent .\n",
      "= they re leaving .\n",
      "< they re coming .\n",
      "\n",
      "************************* iter44000 *************************\n",
      "loss 0.4811\n",
      "> je te le laisse .\n",
      "= i m leaving it to you .\n",
      "< i m leaving it to .\n",
      "\n",
      "************************* iter45000 *************************\n",
      "loss 0.7855\n",
      "> nous sommes malchanceuses .\n",
      "= we re unlucky .\n",
      "< we re sloshed .\n",
      "\n",
      "************************* iter46000 *************************\n",
      "loss 1.9771\n",
      "> je suis heureux que tu aies apprecie .\n",
      "= i m glad you enjoyed it .\n",
      "< i m glad you liked it .\n",
      "\n",
      "************************* iter47000 *************************\n",
      "loss 7.6306\n",
      "> c est une coriace .\n",
      "= she s a tough one .\n",
      "< she s a beauty .\n",
      "\n",
      "************************* iter48000 *************************\n",
      "loss 2.8691\n",
      "> tu n es plus un enfant .\n",
      "= you are not a child any more .\n",
      "< you are not a child child .\n",
      "\n",
      "************************* iter49000 *************************\n",
      "loss 10.0391\n",
      "> nous sommes en guerre .\n",
      "= we are at war .\n",
      "< we re in . .\n",
      "\n",
      "************************* iter50000 *************************\n",
      "loss 1.6289\n",
      "> je ne suis pas institutrice .\n",
      "= i m not a teacher .\n",
      "< i m not a teacher .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcd9299dac8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iters = 50000\n",
    "print_every = 1000\n",
    "plot_every =100\n",
    "\n",
    "plot_losses = []\n",
    "print_loss_total = 0  # Reset every print_every\n",
    "plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "\n",
    "for iter in range(1, n_iters+1):\n",
    "    # Load data\n",
    "    training_pair = training_pairs[iter-1]\n",
    "    input_tensor = training_pair[0]\n",
    "    target_tensor = training_pair[1]\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    #############\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #############\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = 0\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    #############\n",
    "    #hidden state initialization\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    decoder_hidden = decoder.initHidden()\n",
    "    #############\n",
    "    encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_dim, device=device)\n",
    "    #############\n",
    "    #encoder로 부터 output과 hidden을 추출하여 output을 배열에 넣어준다.\n",
    "    for i in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_output.reshape(-1)\n",
    "    #############\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    #############\n",
    "    decoder_hidden = encoder_hidden\n",
    "    #0.5의 확률로 랜덤하게 teacher_forcing이 되도록 했다.\n",
    "    use_teacher_forcing=random.random()>teacher_forcing_ratio\n",
    "    if use_teacher_forcing:#teacher forcing이 될 때    \n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[i])\n",
    "            decoder_input = target_tensor[i] #real target output이 다음 input이 되도록\n",
    "    else:#teacher forcing이 되지 않을 때\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[i])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            #decoder가 추측한 단어가 다음 input이 되도록\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            if topi.item() == EOS_token:\n",
    "                break\n",
    "    #############\n",
    "\n",
    "    # Backward pass\n",
    "    #############\n",
    "    loss.backward()\n",
    "    #############\n",
    "\n",
    "    # Updating parameters\n",
    "    #############\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    #############\n",
    "    \n",
    "    print_loss_total += loss.item() / target_length\n",
    "    plot_loss_total += loss.item() / target_length\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('*'*25, 'iter%d'%iter, '*'*25)\n",
    "        print('loss %.4f'%loss)\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        evaluateRandomly()\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "\n",
    "#################################################\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(plot_losses)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EEE4423_lab11_Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Full on Python 3.6 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
